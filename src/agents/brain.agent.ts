import { runLLM } from "./llm.agent";
import { BRAIN_PROMPT } from "./brain.prompt";
import { extractJson } from "../utils/safe-json";
import { getPersonality } from "../personality/personality.store";
import { getMemorySummary } from "../memory/summary.store";
import { getRecentTurns } from "../memory/rolling.store";

async function sleep(ms: number) {
  return new Promise((r) => setTimeout(r, ms));
}

export async function runBrain(userId: string, text: string) {
  const personality = getPersonality(userId);
  const recent = getRecentTurns(userId);

  let lastError: any;

  for (let attempt = 1; attempt <= 2; attempt++) {
    try {
      const raw = await runLLM(`
${BRAIN_PROMPT}

Mensagem do usu치rio:
"${text}"

칔ltimas mensagens da conversa (para continuidade):
Use esse hist칩rico APENAS para manter continuidade.
N칚o trate isso como mem칩ria permanente.
${
  recent
    .map((t) => `${t.role === "user" ? "Usu치rio" : "Lessa"}: ${t.text}`)
    .join("\n") || "Nenhuma"
}


Resumo persistente do usu치rio:
${getMemorySummary(userId) ?? "Ainda n칚o dispon칤vel"}


Estilo de conversa da Lessa com este usu치rio:
- Formalidade: ${personality.formality}
- Verbosidade: ${personality.verbosity}
- Curiosidade: ${personality.curiosity}
- Intimidade: ${personality.intimacy}

Instru칞칫es:
- Ajuste o tom de resposta com base nesses valores
- Valores baixos = casual / curto
- Valores altos = mais elaborado

`);
      return extractJson(raw);
    } catch (err: any) {
      lastError = err;
      if (err?.status === 503) {
        await sleep(400 * attempt); // backoff simples
        continue;
      }
      throw err;
    }
  }

  // fallback humano (degrada칞칚o graciosa)
  return {
    mode: "reply",
    reply: "T칪 aqui 游뗵 s칩 tive um pequeno engasgo agora. Continua.",
    storeMemory: false,
    memories: [],
    profile: {},
  };
}
